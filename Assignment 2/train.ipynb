{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ee8c73-4fe7-4383-b68e-cb5a8d514f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, auc, precision_recall_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7bc726e-0efc-4065-bbbd-4e4e4d8d8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6aa24d5-9e13-4b6c-9bcd-d6955f3d7a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/04 23:24:36 INFO mlflow.tracking.fluent: Experiment with name 'Spam Classifier Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('file:///C:/Users/chaud/OneDrive/Desktop/Applied ML/Assignment '\n",
       " '2/mlruns/918975700612171805'), creation_time=1741110876391, experiment_id='918975700612171805', last_update_time=1741110876391, lifecycle_stage='active', name='Spam Classifier Experiment', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_tracking_uri('file:mlruns')  # Local directory for tracking\n",
    "mlflow.set_experiment('Spam Classifier Experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6b9e513-6d9f-4b9b-8d04-5b56195970c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data splits\n",
    "train = pd.read_csv('train.csv').dropna()\n",
    "validation = pd.read_csv('validation.csv').dropna()\n",
    "test = pd.read_csv('test.csv').dropna()\n",
    "\n",
    "# Vectorizing the text data using TF-IDF\n",
    "def vectorize_data(train_data, validation_data, test_data):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    X_train = vectorizer.fit_transform(train_data['text'])\n",
    "    X_validation = vectorizer.transform(validation_data['text'])\n",
    "    X_test = vectorizer.transform(test_data['text'])\n",
    "    return X_train, X_validation, X_test, vectorizer\n",
    "\n",
    "X_train, X_validation, X_test, vectorizer = vectorize_data(train, validation, test)\n",
    "\n",
    "# Function to calculate AUCPR\n",
    "def calculate_aucpr(model, X, y_true):\n",
    "    y_scores = model.predict_proba(X)[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores, pos_label=1)\n",
    "    aucpr = auc(recall, precision)\n",
    "    return aucpr\n",
    "\n",
    "# Model training, tracking, and registration with MLflow\n",
    "def train_and_track_model(model_name, model, param_grid, X_train, y_train, X_validation, y_validation):\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        # Hyperparameter tuning with GridSearchCV\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring='recall', cv=5, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluation on validation set\n",
    "        val_precision, val_recall, val_accuracy = evaluate_model(best_model, X_validation, y_validation)\n",
    "        aucpr = calculate_aucpr(best_model, X_validation, y_validation)\n",
    "\n",
    "        print(f'{model_name} - AUCPR: {aucpr:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Log parameters, metrics, and model in MLflow\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\n",
    "            'precision': val_precision,\n",
    "            'recall': val_recall,\n",
    "            'accuracy': val_accuracy,\n",
    "            'aucpr': aucpr\n",
    "        })\n",
    "\n",
    "        # Log and register the model\n",
    "        signature = infer_signature(X_validation, best_model.predict(X_validation))\n",
    "        mlflow.sklearn.log_model(best_model, 'model', signature=signature)\n",
    "        mlflow.set_tag('model_name', model_name)\n",
    "\n",
    "        model_uri = f'runs:/{run.info.run_id}/model'\n",
    "        mlflow.register_model(model_uri=model_uri, name='SpamClassifierModel')\n",
    "\n",
    "        return best_model\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, X, y, average='binary'):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred, pos_label=1, average=average)\n",
    "    precision = precision_score(y, y_pred, pos_label=1, average=average)\n",
    "    return precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e8b51cf-c83a-440a-b812-32a5ba872ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - AUCPR: 0.9875, Precision: 0.9826, Recall: 0.9113, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'SpamClassifierModel'.\n",
      "Created version '1' of model 'SpamClassifierModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - AUCPR: 0.9892, Precision: 0.9910, Recall: 0.8871, Accuracy: 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'SpamClassifierModel' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'SpamClassifierModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - AUCPR: 0.9913, Precision: 0.9825, Recall: 0.9032, Accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'SpamClassifierModel' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'SpamClassifierModel'.\n"
     ]
    }
   ],
   "source": [
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    'Naive Bayes': (MultinomialNB(), {'alpha': [0.01, 0.1, 1, 10]}),\n",
    "    'Logistic Regression': (LogisticRegression(), {'C': [0.01, 0.1, 1, 10], 'solver': ['liblinear']}),\n",
    "    'SVM': (SVC(probability=True), {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']})\n",
    "}\n",
    "\n",
    "# Train, track, and register all models\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    train_and_track_model(model_name, model, param_grid, X_train, train['category'], X_validation, validation['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e502c3-2f4f-4950-97d7-39720c286eee",
   "metadata": {},
   "source": [
    "## Loading SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6059a295-b4e8-45df-af39-799ff3b5c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUCPR: 0.9541\n"
     ]
    }
   ],
   "source": [
    "logged_model = 'runs:/c306231fc2f34d07ada87e4d43432eaa/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Get predictions and convert 'spam' to 1 and 'ham' to 0\n",
    "y_scores = model.predict(X_test)\n",
    "y_scores = (y_scores == 1).astype(int)\n",
    "\n",
    "# Convert true labels to 1 for 'spam' and 0 for 'ham'\n",
    "y_true = (test['category'] == 1).astype(int)\n",
    "\n",
    "# Calculate precision, recall, and AUCPR\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "aucpr = auc(recall, precision)\n",
    "\n",
    "# Print the model selection metric AUCPR\n",
    "print(f\"Model AUCPR: {aucpr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe55996-13f3-4da3-8b58-1b7a8939117d",
   "metadata": {},
   "source": [
    "## Loading Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f640c61-817a-42b7-95a9-7602bdb119f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUCPR: 0.9425\n"
     ]
    }
   ],
   "source": [
    "logged_model = 'runs:/7c8ce34cb7b541b4b4933fbe7b794d44/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Get predictions and convert 'spam' to 1 and 'ham' to 0\n",
    "y_scores = model.predict(X_test)\n",
    "y_scores = (y_scores == 1).astype(int)\n",
    "\n",
    "# Convert true labels to 1 for 'spam' and 0 for 'ham'\n",
    "y_true = (test['category'] == 1).astype(int)\n",
    "\n",
    "# Calculate precision, recall, and AUCPR\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "aucpr = auc(recall, precision)\n",
    "\n",
    "# Print the model selection metric AUCPR\n",
    "print(f\"Model AUCPR: {aucpr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e020631a-b5c6-4278-8ac0-f3b74caa6f64",
   "metadata": {},
   "source": [
    "## Loading Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f9c66a4-53bd-4893-bd57-a467a4d9f13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUCPR: 0.9582\n"
     ]
    }
   ],
   "source": [
    "logged_model = 'runs:/4235cd7e4757424f990eb67d79f2c92b/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Get predictions and convert 'spam' to 1 and 'ham' to 0\n",
    "y_scores = model.predict(X_test)\n",
    "y_scores = (y_scores == 1).astype(int)\n",
    "\n",
    "# Convert true labels to 1 for 'spam' and 0 for 'ham'\n",
    "y_true = (test['category'] == 1).astype(int)\n",
    "\n",
    "# Calculate precision, recall, and AUCPR\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "aucpr = auc(recall, precision)\n",
    "\n",
    "# Print the model selection metric AUCPR\n",
    "print(f\"Model AUCPR: {aucpr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b5111-2329-4ea6-a21a-7ed33163c8bb",
   "metadata": {},
   "source": [
    "## Best Model: Naive Bayes with AUCPR: 0.9582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8056b0f-bfa2-4a04-8923-10e680c048c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
